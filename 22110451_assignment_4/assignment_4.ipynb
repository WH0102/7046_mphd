{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip FLAML \"flaml[spark]\" setuptools wheel optuna optuna-integration openml xgboost catboost imbalanced-learn\n",
    "# %pip install --upgrade \"scikit-learn==1.1.2\"\n",
    "# %pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 553 entries, 0 to 552\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Patient_ID  553 non-null    int64  \n",
      " 1   Age         553 non-null    int64  \n",
      " 2   TB          553 non-null    float64\n",
      " 3   DB          553 non-null    float64\n",
      " 4   ALP         553 non-null    int64  \n",
      " 5   ALT         553 non-null    int64  \n",
      " 6   AST         553 non-null    int64  \n",
      " 7   TP          553 non-null    float64\n",
      " 8   ALB         553 non-null    float64\n",
      " 9   AGR         553 non-null    object \n",
      " 10  Disease     553 non-null    int64  \n",
      " 11  Ethnic      553 non-null    int64  \n",
      " 12  Gender      553 non-null    object \n",
      " 13  bmi         553 non-null    int64  \n",
      "dtypes: float64(4), int64(8), object(2)\n",
      "memory usage: 60.6+ KB\n",
      "Missing data detected for columns AGR.\n",
      "Summary of the missing values from the dataframe =\n",
      "+------------------------------+-------+--------------------+\n",
      "|                              | count | missing_percentage |\n",
      "+------------------------------+-------+--------------------+\n",
      "|             AGR              |  4.0  |        0.72        |\n",
      "| All_rows_with_missing_values |  4.0  |        0.72        |\n",
      "+------------------------------+-------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# To allow own package to be imported\n",
    "import sys\n",
    "import os\n",
    "if os.path.dirname(os.getcwd()) not in sys.path:\n",
    "    sys.path.append(os.path.dirname(os.getcwd()))\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(action = \"ignore\")\n",
    "\n",
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import plotly.express as px\n",
    "import wh0102 as mphd\n",
    "\n",
    "# Prepare the data dictionary\n",
    "data_dictionary = {\n",
    "    \"Ethnic\":{0:\"Malay\", 1:\"Chinese\", 2:\"Indian\"},\n",
    "    \"bmi\":{0:\"Normal BMI\", 1:\"Overweight\"},\n",
    "    \"Disease\":{0:\"No liver disease\", 1:\"Have Liver Disease\"},\n",
    "    \"Gender\":{0:\"Female\", 1:\"Male\"}\n",
    "}\n",
    "\n",
    "# Rename for easier references\n",
    "column_to_be_rename = {\"Sgot\":\"ALT\",\n",
    "                       \"Sgpt\":\"AST\",\n",
    "                       \"Alkphos\":\"ALP\"}\n",
    "\n",
    "# Prepare the variables\n",
    "dependent_variable = \"Disease\"\n",
    "independent_demographic = (\"Age\", \"Gender\", \"Ethnic\", \"bmi\",)\n",
    "independent_investigations = (\"AGR\", \"ALB\", \"TP\", \"TB\", \"DB\", \"ALP\", \"ALT\", \"AST\",)\n",
    "independent_continous = (independent_demographic[0],) + independent_investigations\n",
    "independent_categorical = independent_demographic[1:]\n",
    "independent_variables = independent_demographic + independent_investigations\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(r\"assignment4.csv\")\n",
    "\n",
    "# Rename the column name\n",
    "df = df.rename(columns = column_to_be_rename)\n",
    "\n",
    "# To reassign the categorical value\n",
    "for column in [key for key in data_dictionary.keys() if key != \"Gender\"]:\n",
    "    df.loc[:,column] = df.loc[:,column] - 1\n",
    "\n",
    "# Print the information\n",
    "df.info()\n",
    "\n",
    "# To delete after this\n",
    "missing_df = mphd.missing_values.analyse_missing_row(df)\n",
    "df = mphd.categorical_data.label_encode(df = df, columns = \"Gender\", convert_numeric=True)\n",
    "df = mphd.missing_values.mice_imputation(df = df, columns = \"AGR\")\n",
    "# df.drop(columns = [\"Patient_ID\"]).to_csv(r\"imputed_assignment_4.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 05-26 21:17:37] {1680} INFO - task = classification\n",
      "[flaml.automl.logger: 05-26 21:17:37] {1691} INFO - Evaluation method: cv\n",
      "[flaml.automl.logger: 05-26 21:17:37] {1789} INFO - Minimizing error metric: 1-roc_auc\n",
      "[flaml.automl.logger: 05-26 21:17:37] {1901} INFO - List of ML learners in AutoML Run: ['lgbm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed a `space` parameter to OptunaSearch that contained unresolved search space definitions. OptunaSearch should however be instantiated with fully configured search spaces only. To use Ray Tune's automatic search space conversion, pass the space definition as part of the `config` argument to `tune.run()` instead.\n",
      "[I 2024-05-26 21:17:37,482] A new study created in memory with name: optuna\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-26 21:17:37,539] A new study created in memory with name: optuna\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.tune.tune: 05-26 21:17:37] {735} INFO - Number of trials: 1/1000000, 1 RUNNING, 0 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:37] {755} INFO - Brief result: {'pred_time': 1.1387738314541904e-05, 'wall_clock_time': 0.466646671295166, 'metric_for_logging': {'pred_time': 1.1387738314541904e-05}, 'val_loss': 0.19427978253996234, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269161E09B0>}\n",
      "[flaml.tune.tune: 05-26 21:17:37] {735} INFO - Number of trials: 2/1000000, 1 RUNNING, 1 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:38] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 0.7130277156829834, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.18690741999837718, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916AA8470>}\n",
      "[flaml.tune.tune: 05-26 21:17:38] {735} INFO - Number of trials: 3/1000000, 1 RUNNING, 2 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:38] {755} INFO - Brief result: {'pred_time': 3.3470717343417078e-06, 'wall_clock_time': 1.2370274066925049, 'metric_for_logging': {'pred_time': 3.3470717343417078e-06}, 'val_loss': 0.18175687396998877, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269161E03B0>}\n",
      "[flaml.tune.tune: 05-26 21:17:38] {735} INFO - Number of trials: 4/1000000, 1 RUNNING, 3 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:39] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 1.8489782810211182, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.17993160305428943, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916693560>}\n",
      "[flaml.tune.tune: 05-26 21:17:39] {735} INFO - Number of trials: 5/1000000, 1 RUNNING, 4 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:39] {755} INFO - Brief result: {'pred_time': 4.616563605093249e-05, 'wall_clock_time': 2.1268303394317627, 'metric_for_logging': {'pred_time': 4.616563605093249e-05}, 'val_loss': 0.17613689461917914, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269161E36B0>}\n",
      "[flaml.tune.tune: 05-26 21:17:39] {735} INFO - Number of trials: 6/1000000, 1 RUNNING, 5 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:39] {755} INFO - Brief result: {'pred_time': 4.0007100285499894e-05, 'wall_clock_time': 2.4816346168518066, 'metric_for_logging': {'pred_time': 4.0007100285499894e-05}, 'val_loss': 0.18634845089102095, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269161E18B0>}\n",
      "[flaml.tune.tune: 05-26 21:17:39] {735} INFO - Number of trials: 7/1000000, 1 RUNNING, 6 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:40] {755} INFO - Brief result: {'pred_time': 4.662125541679219e-05, 'wall_clock_time': 2.7269625663757324, 'metric_for_logging': {'pred_time': 4.662125541679219e-05}, 'val_loss': 0.33245224524970696, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916AA8770>}\n",
      "[flaml.tune.tune: 05-26 21:17:40] {735} INFO - Number of trials: 8/1000000, 1 RUNNING, 7 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:40] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 2.944979429244995, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.20000307779260726, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916AB02C0>}\n",
      "[flaml.tune.tune: 05-26 21:17:40] {735} INFO - Number of trials: 9/1000000, 1 RUNNING, 8 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:40] {755} INFO - Brief result: {'pred_time': 4.115575911197526e-05, 'wall_clock_time': 3.2632291316986084, 'metric_for_logging': {'pred_time': 4.115575911197526e-05}, 'val_loss': 0.17709408812000038, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916AB0FE0>}\n",
      "[flaml.tune.tune: 05-26 21:17:40] {735} INFO - Number of trials: 10/1000000, 1 RUNNING, 9 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:40] {755} INFO - Brief result: {'pred_time': 3.551569851962003e-05, 'wall_clock_time': 3.494107723236084, 'metric_for_logging': {'pred_time': 3.551569851962003e-05}, 'val_loss': 0.5, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916AB15E0>}\n",
      "[flaml.tune.tune: 05-26 21:17:40] {735} INFO - Number of trials: 11/1000000, 1 RUNNING, 10 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:41] {755} INFO - Brief result: {'pred_time': 1.0142165623354108e-05, 'wall_clock_time': 3.8491342067718506, 'metric_for_logging': {'pred_time': 1.0142165623354108e-05}, 'val_loss': 0.18000833801997213, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916AB2450>}\n",
      "[flaml.tune.tune: 05-26 21:17:41] {735} INFO - Number of trials: 12/1000000, 1 RUNNING, 11 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:41] {755} INFO - Brief result: {'pred_time': 5.739385431463068e-06, 'wall_clock_time': 4.098011255264282, 'metric_for_logging': {'pred_time': 5.739385431463068e-06}, 'val_loss': 0.34215750463767386, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916AB3020>}\n",
      "[flaml.tune.tune: 05-26 21:17:41] {735} INFO - Number of trials: 13/1000000, 1 RUNNING, 12 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:41] {755} INFO - Brief result: {'pred_time': 8.2159736426785e-06, 'wall_clock_time': 4.330624341964722, 'metric_for_logging': {'pred_time': 8.2159736426785e-06}, 'val_loss': 0.1669637436030879, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916AB36E0>}\n",
      "[flaml.tune.tune: 05-26 21:17:41] {735} INFO - Number of trials: 14/1000000, 1 RUNNING, 13 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:41] {755} INFO - Brief result: {'pred_time': 6.277149008535632e-05, 'wall_clock_time': 4.544353008270264, 'metric_for_logging': {'pred_time': 6.277149008535632e-05}, 'val_loss': 0.17842957031217216, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916AB3560>}\n",
      "[flaml.tune.tune: 05-26 21:17:41] {735} INFO - Number of trials: 15/1000000, 1 RUNNING, 14 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:42] {755} INFO - Brief result: {'pred_time': 2.1374627445520978e-05, 'wall_clock_time': 4.7983527183532715, 'metric_for_logging': {'pred_time': 2.1374627445520978e-05}, 'val_loss': 0.17718670169754253, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B19010>}\n",
      "[flaml.tune.tune: 05-26 21:17:42] {735} INFO - Number of trials: 16/1000000, 1 RUNNING, 15 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:42] {755} INFO - Brief result: {'pred_time': 3.552165898409757e-05, 'wall_clock_time': 5.093285799026489, 'metric_for_logging': {'pred_time': 3.552165898409757e-05}, 'val_loss': 0.17611555992042513, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B191F0>}\n",
      "[flaml.tune.tune: 05-26 21:17:42] {735} INFO - Number of trials: 17/1000000, 1 RUNNING, 16 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:42] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 5.309611082077026, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.21825767559506323, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B19AC0>}\n",
      "[flaml.tune.tune: 05-26 21:17:42] {735} INFO - Number of trials: 18/1000000, 1 RUNNING, 17 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:42] {755} INFO - Brief result: {'pred_time': 4.494592045130355e-06, 'wall_clock_time': 5.510797023773193, 'metric_for_logging': {'pred_time': 4.494592045130355e-06}, 'val_loss': 0.20934725614789076, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B18290>}\n",
      "[flaml.tune.tune: 05-26 21:17:42] {735} INFO - Number of trials: 19/1000000, 1 RUNNING, 18 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:43] {755} INFO - Brief result: {'pred_time': 6.341398432013694e-06, 'wall_clock_time': 5.811906814575195, 'metric_for_logging': {'pred_time': 6.341398432013694e-06}, 'val_loss': 0.16502914110000308, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B18F80>}\n",
      "[flaml.tune.tune: 05-26 21:17:43] {735} INFO - Number of trials: 20/1000000, 1 RUNNING, 19 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:43] {755} INFO - Brief result: {'pred_time': 6.737334004948649e-06, 'wall_clock_time': 6.030365943908691, 'metric_for_logging': {'pred_time': 6.737334004948649e-06}, 'val_loss': 0.316791177367592, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B1AFF0>}\n",
      "[flaml.tune.tune: 05-26 21:17:43] {735} INFO - Number of trials: 21/1000000, 1 RUNNING, 20 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:43] {755} INFO - Brief result: {'pred_time': 5.9171156449751425e-06, 'wall_clock_time': 6.398387670516968, 'metric_for_logging': {'pred_time': 5.9171156449751425e-06}, 'val_loss': 0.1689692752358009, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B1BEC0>}\n",
      "[flaml.tune.tune: 05-26 21:17:43] {735} INFO - Number of trials: 22/1000000, 1 RUNNING, 21 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:44] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 6.646249532699585, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.17141185341872808, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B34170>}\n",
      "[flaml.tune.tune: 05-26 21:17:44] {735} INFO - Number of trials: 23/1000000, 1 RUNNING, 22 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:44] {755} INFO - Brief result: {'pred_time': 3.038309324262578e-05, 'wall_clock_time': 7.042485952377319, 'metric_for_logging': {'pred_time': 3.038309324262578e-05}, 'val_loss': 0.184719529153691, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B34DA0>}\n",
      "[flaml.tune.tune: 05-26 21:17:44] {735} INFO - Number of trials: 24/1000000, 1 RUNNING, 23 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:44] {755} INFO - Brief result: {'pred_time': 1.6442754051902078e-05, 'wall_clock_time': 7.554143190383911, 'metric_for_logging': {'pred_time': 1.6442754051902078e-05}, 'val_loss': 0.1556529257216724, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B35BE0>}\n",
      "[flaml.tune.tune: 05-26 21:17:44] {735} INFO - Number of trials: 25/1000000, 1 RUNNING, 24 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:45] {755} INFO - Brief result: {'pred_time': 1.4246727765154424e-05, 'wall_clock_time': 7.848674535751343, 'metric_for_logging': {'pred_time': 1.4246727765154424e-05}, 'val_loss': 0.16992863718141352, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B360C0>}\n",
      "[flaml.tune.tune: 05-26 21:17:45] {735} INFO - Number of trials: 26/1000000, 1 RUNNING, 25 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:45] {755} INFO - Brief result: {'pred_time': 1.4631935719693645e-05, 'wall_clock_time': 8.21276307106018, 'metric_for_logging': {'pred_time': 1.4631935719693645e-05}, 'val_loss': 0.18572939487799353, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B369F0>}\n",
      "[flaml.tune.tune: 05-26 21:17:45] {735} INFO - Number of trials: 27/1000000, 1 RUNNING, 26 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:46] {755} INFO - Brief result: {'pred_time': 4.095227530833041e-05, 'wall_clock_time': 8.846152782440186, 'metric_for_logging': {'pred_time': 4.095227530833041e-05}, 'val_loss': 0.17752546873382413, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B37530>}\n",
      "[flaml.tune.tune: 05-26 21:17:46] {735} INFO - Number of trials: 28/1000000, 1 RUNNING, 27 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:47] {755} INFO - Brief result: {'pred_time': 6.022778424349698e-06, 'wall_clock_time': 9.71119213104248, 'metric_for_logging': {'pred_time': 6.022778424349698e-06}, 'val_loss': 0.16197778952934955, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B5CA10>}\n",
      "[flaml.tune.tune: 05-26 21:17:47] {735} INFO - Number of trials: 29/1000000, 1 RUNNING, 28 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:47] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 9.99686312675476, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.18715965909249888, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B5C860>}\n",
      "[flaml.tune.tune: 05-26 21:17:47] {735} INFO - Number of trials: 30/1000000, 1 RUNNING, 29 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:47] {755} INFO - Brief result: {'pred_time': 7.069972976357262e-05, 'wall_clock_time': 10.561567306518555, 'metric_for_logging': {'pred_time': 7.069972976357262e-05}, 'val_loss': 0.2834589632315703, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B5C770>}\n",
      "[flaml.tune.tune: 05-26 21:17:47] {735} INFO - Number of trials: 31/1000000, 1 RUNNING, 30 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:48] {755} INFO - Brief result: {'pred_time': 3.55341217734597e-05, 'wall_clock_time': 10.963733434677124, 'metric_for_logging': {'pred_time': 3.55341217734597e-05}, 'val_loss': 0.1693865259835646, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B5E570>}\n",
      "[flaml.tune.tune: 05-26 21:17:48] {735} INFO - Number of trials: 32/1000000, 1 RUNNING, 31 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:48] {755} INFO - Brief result: {'pred_time': 4.4886985521638e-06, 'wall_clock_time': 11.36161732673645, 'metric_for_logging': {'pred_time': 4.4886985521638e-06}, 'val_loss': 0.16821857363898612, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B5CEF0>}\n",
      "[flaml.tune.tune: 05-26 21:17:48] {735} INFO - Number of trials: 33/1000000, 1 RUNNING, 32 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:49] {755} INFO - Brief result: {'pred_time': 9.039717139457413e-06, 'wall_clock_time': 11.907537937164307, 'metric_for_logging': {'pred_time': 9.039717139457413e-06}, 'val_loss': 0.1730504282328714, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B5F440>}\n",
      "[flaml.tune.tune: 05-26 21:17:49] {735} INFO - Number of trials: 34/1000000, 1 RUNNING, 33 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:49] {755} INFO - Brief result: {'pred_time': 4.238703034140847e-05, 'wall_clock_time': 12.214385747909546, 'metric_for_logging': {'pred_time': 4.238703034140847e-05}, 'val_loss': 0.2942886661686238, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B5F6B0>}\n",
      "[flaml.tune.tune: 05-26 21:17:49] {735} INFO - Number of trials: 35/1000000, 1 RUNNING, 34 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:50] {755} INFO - Brief result: {'pred_time': 1.8281706507042794e-05, 'wall_clock_time': 13.078573226928711, 'metric_for_logging': {'pred_time': 1.8281706507042794e-05}, 'val_loss': 0.20002434254152926, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B7C800>}\n",
      "[flaml.tune.tune: 05-26 21:17:50] {735} INFO - Number of trials: 36/1000000, 1 RUNNING, 35 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:51] {755} INFO - Brief result: {'pred_time': 2.040754665027965e-05, 'wall_clock_time': 13.87399435043335, 'metric_for_logging': {'pred_time': 2.040754665027965e-05}, 'val_loss': 0.1655132638871402, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B7CA70>}\n",
      "[flaml.tune.tune: 05-26 21:17:51] {735} INFO - Number of trials: 37/1000000, 1 RUNNING, 36 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:51] {755} INFO - Brief result: {'pred_time': 5.267838413795728e-05, 'wall_clock_time': 14.173907041549683, 'metric_for_logging': {'pred_time': 5.267838413795728e-05}, 'val_loss': 0.1698177666977244, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B7D6A0>}\n",
      "[flaml.tune.tune: 05-26 21:17:51] {735} INFO - Number of trials: 38/1000000, 1 RUNNING, 37 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:52] {755} INFO - Brief result: {'pred_time': 1.6973259743679776e-06, 'wall_clock_time': 14.874233484268188, 'metric_for_logging': {'pred_time': 1.6973259743679776e-06}, 'val_loss': 0.1524847579316114, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B7DF40>}\n",
      "[flaml.tune.tune: 05-26 21:17:52] {735} INFO - Number of trials: 39/1000000, 1 RUNNING, 38 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:52] {755} INFO - Brief result: {'pred_time': 8.134821827492017e-05, 'wall_clock_time': 15.357137203216553, 'metric_for_logging': {'pred_time': 8.134821827492017e-05}, 'val_loss': 0.16671451235174134, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B7DC10>}\n",
      "[flaml.tune.tune: 05-26 21:17:52] {735} INFO - Number of trials: 40/1000000, 1 RUNNING, 39 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:53] {755} INFO - Brief result: {'pred_time': 2.7153355595527317e-05, 'wall_clock_time': 15.956954956054688, 'metric_for_logging': {'pred_time': 2.7153355595527317e-05}, 'val_loss': 0.1788584327320446, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B7F1D0>}\n",
      "[flaml.tune.tune: 05-26 21:17:53] {735} INFO - Number of trials: 41/1000000, 1 RUNNING, 40 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:54] {755} INFO - Brief result: {'pred_time': 4.523313082031624e-05, 'wall_clock_time': 16.793536901474, 'metric_for_logging': {'pred_time': 4.523313082031624e-05}, 'val_loss': 0.16671640099720486, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B7D670>}\n",
      "[flaml.tune.tune: 05-26 21:17:54] {735} INFO - Number of trials: 42/1000000, 1 RUNNING, 41 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:54] {755} INFO - Brief result: {'pred_time': 1.123781954304556e-05, 'wall_clock_time': 17.506600618362427, 'metric_for_logging': {'pred_time': 1.123781954304556e-05}, 'val_loss': 0.156920836376151, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BB09B0>}\n",
      "[flaml.tune.tune: 05-26 21:17:54] {735} INFO - Number of trials: 43/1000000, 1 RUNNING, 42 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:55] {755} INFO - Brief result: {'pred_time': 5.124660020463922e-06, 'wall_clock_time': 18.223230361938477, 'metric_for_logging': {'pred_time': 5.124660020463922e-06}, 'val_loss': 0.16944031740435767, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916B5D9D0>}\n",
      "[flaml.tune.tune: 05-26 21:17:55] {735} INFO - Number of trials: 44/1000000, 1 RUNNING, 43 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:56] {755} INFO - Brief result: {'pred_time': 6.738405549124386e-06, 'wall_clock_time': 18.828526258468628, 'metric_for_logging': {'pred_time': 6.738405549124386e-06}, 'val_loss': 0.18753892708149716, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BB20F0>}\n",
      "[flaml.tune.tune: 05-26 21:17:56] {735} INFO - Number of trials: 45/1000000, 1 RUNNING, 44 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:57] {755} INFO - Brief result: {'pred_time': 6.009304974003637e-05, 'wall_clock_time': 20.11634087562561, 'metric_for_logging': {'pred_time': 6.009304974003637e-05}, 'val_loss': 0.22957758695463615, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BB0CB0>}\n",
      "[flaml.tune.tune: 05-26 21:17:57] {735} INFO - Number of trials: 46/1000000, 1 RUNNING, 45 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:58] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 21.139134168624878, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.1722012372726281, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BB3560>}\n",
      "[flaml.tune.tune: 05-26 21:17:58] {735} INFO - Number of trials: 47/1000000, 1 RUNNING, 46 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:17:59] {755} INFO - Brief result: {'pred_time': 7.111050865866921e-05, 'wall_clock_time': 21.662030696868896, 'metric_for_logging': {'pred_time': 7.111050865866921e-05}, 'val_loss': 0.15890496336027807, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BD4680>}\n",
      "[flaml.tune.tune: 05-26 21:17:59] {735} INFO - Number of trials: 48/1000000, 1 RUNNING, 47 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:00] {755} INFO - Brief result: {'pred_time': 1.594586805863814e-05, 'wall_clock_time': 22.861168384552002, 'metric_for_logging': {'pred_time': 1.594586805863814e-05}, 'val_loss': 0.18732942733471555, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BD5280>}\n",
      "[flaml.tune.tune: 05-26 21:18:00] {735} INFO - Number of trials: 49/1000000, 1 RUNNING, 48 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:00] {755} INFO - Brief result: {'pred_time': 3.034045065508678e-05, 'wall_clock_time': 23.346217155456543, 'metric_for_logging': {'pred_time': 3.034045065508678e-05}, 'val_loss': 0.21825767559506323, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BD45F0>}\n",
      "[flaml.tune.tune: 05-26 21:18:00] {735} INFO - Number of trials: 50/1000000, 1 RUNNING, 49 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:01] {755} INFO - Brief result: {'pred_time': 3.9054588838057086e-05, 'wall_clock_time': 23.999510526657104, 'metric_for_logging': {'pred_time': 3.9054588838057086e-05}, 'val_loss': 0.16528991407362642, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BB18B0>}\n",
      "[flaml.tune.tune: 05-26 21:18:01] {735} INFO - Number of trials: 51/1000000, 1 RUNNING, 50 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:02] {755} INFO - Brief result: {'pred_time': 4.107388948395742e-05, 'wall_clock_time': 25.00919270515442, 'metric_for_logging': {'pred_time': 4.107388948395742e-05}, 'val_loss': 0.1527199292667299, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BD73E0>}\n",
      "[flaml.tune.tune: 05-26 21:18:02] {735} INFO - Number of trials: 52/1000000, 1 RUNNING, 51 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:02] {755} INFO - Brief result: {'pred_time': 3.5124146536494904e-05, 'wall_clock_time': 25.527949571609497, 'metric_for_logging': {'pred_time': 3.5124146536494904e-05}, 'val_loss': 0.16471324765877915, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BD7A10>}\n",
      "[flaml.tune.tune: 05-26 21:18:02] {735} INFO - Number of trials: 53/1000000, 1 RUNNING, 52 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:04] {755} INFO - Brief result: {'pred_time': 4.494592045130355e-06, 'wall_clock_time': 27.058286905288696, 'metric_for_logging': {'pred_time': 4.494592045130355e-06}, 'val_loss': 0.16097442913942123, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BD7DA0>}\n",
      "[flaml.tune.tune: 05-26 21:18:04] {735} INFO - Number of trials: 54/1000000, 1 RUNNING, 53 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:04] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 27.375707387924194, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.16297310568860016, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BF8920>}\n",
      "[flaml.tune.tune: 05-26 21:18:04] {735} INFO - Number of trials: 55/1000000, 1 RUNNING, 54 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:05] {755} INFO - Brief result: {'pred_time': 7.064961680839935e-05, 'wall_clock_time': 27.84561014175415, 'metric_for_logging': {'pred_time': 7.064961680839935e-05}, 'val_loss': 0.30077343529220835, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BF9190>}\n",
      "[flaml.tune.tune: 05-26 21:18:05] {735} INFO - Number of trials: 56/1000000, 1 RUNNING, 55 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:06] {755} INFO - Brief result: {'pred_time': 8.988648318172841e-06, 'wall_clock_time': 28.96175503730774, 'metric_for_logging': {'pred_time': 8.988648318172841e-06}, 'val_loss': 0.15759214491366794, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BF97C0>}\n",
      "[flaml.tune.tune: 05-26 21:18:06] {735} INFO - Number of trials: 57/1000000, 1 RUNNING, 56 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:07] {755} INFO - Brief result: {'pred_time': 4.0054710941490045e-05, 'wall_clock_time': 29.710811138153076, 'metric_for_logging': {'pred_time': 4.0054710941490045e-05}, 'val_loss': 0.18862951491190522, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BF9DF0>}\n",
      "[flaml.tune.tune: 05-26 21:18:07] {735} INFO - Number of trials: 58/1000000, 1 RUNNING, 57 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:07] {755} INFO - Brief result: {'pred_time': 3.96665684171059e-05, 'wall_clock_time': 30.47539734840393, 'metric_for_logging': {'pred_time': 3.96665684171059e-05}, 'val_loss': 0.16267001306662862, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BF8170>}\n",
      "[flaml.tune.tune: 05-26 21:18:07] {735} INFO - Number of trials: 59/1000000, 1 RUNNING, 58 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:09] {755} INFO - Brief result: {'pred_time': 3.9001510871443004e-05, 'wall_clock_time': 31.895657539367676, 'metric_for_logging': {'pred_time': 3.9001510871443004e-05}, 'val_loss': 0.20070719280132288, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BF8E00>}\n",
      "[flaml.tune.tune: 05-26 21:18:09] {735} INFO - Number of trials: 60/1000000, 1 RUNNING, 59 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:09] {755} INFO - Brief result: {'pred_time': 8.74337429167423e-06, 'wall_clock_time': 32.259411573410034, 'metric_for_logging': {'pred_time': 8.74337429167423e-06}, 'val_loss': 0.17239891549780498, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916AAAD80>}\n",
      "[flaml.tune.tune: 05-26 21:18:09] {735} INFO - Number of trials: 61/1000000, 1 RUNNING, 60 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:10] {755} INFO - Brief result: {'pred_time': 2.568960189819336e-06, 'wall_clock_time': 33.27633714675903, 'metric_for_logging': {'pred_time': 2.568960189819336e-06}, 'val_loss': 0.19487939249969924, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BFBCB0>}\n",
      "[flaml.tune.tune: 05-26 21:18:10] {735} INFO - Number of trials: 62/1000000, 1 RUNNING, 61 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:11] {755} INFO - Brief result: {'pred_time': 4.651054542081715e-05, 'wall_clock_time': 33.794328927993774, 'metric_for_logging': {'pred_time': 4.651054542081715e-05}, 'val_loss': 0.16392855044362184, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026916BFBE00>}\n",
      "[flaml.tune.tune: 05-26 21:18:11] {735} INFO - Number of trials: 63/1000000, 1 RUNNING, 62 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:12] {755} INFO - Brief result: {'pred_time': 7.10406086661599e-05, 'wall_clock_time': 35.1921706199646, 'metric_for_logging': {'pred_time': 7.10406086661599e-05}, 'val_loss': 0.1553581571297066, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917030800>}\n",
      "[flaml.tune.tune: 05-26 21:18:12] {735} INFO - Number of trials: 64/1000000, 1 RUNNING, 63 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:13] {755} INFO - Brief result: {'pred_time': 3.512307499231917e-05, 'wall_clock_time': 35.97764205932617, 'metric_for_logging': {'pred_time': 3.512307499231917e-05}, 'val_loss': 0.17546579593115816, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170311F0>}\n",
      "[flaml.tune.tune: 05-26 21:18:13] {735} INFO - Number of trials: 65/1000000, 1 RUNNING, 64 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:13] {755} INFO - Brief result: {'pred_time': 3.552545200694691e-05, 'wall_clock_time': 36.54980731010437, 'metric_for_logging': {'pred_time': 3.552545200694691e-05}, 'val_loss': 0.18221392617214935, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917030620>}\n",
      "[flaml.tune.tune: 05-26 21:18:13] {735} INFO - Number of trials: 66/1000000, 1 RUNNING, 65 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:14] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 37.091991901397705, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.17747755309891744, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917031C10>}\n",
      "[flaml.tune.tune: 05-26 21:18:14] {735} INFO - Number of trials: 67/1000000, 1 RUNNING, 66 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:15] {755} INFO - Brief result: {'pred_time': 4.521916421611657e-06, 'wall_clock_time': 38.210750102996826, 'metric_for_logging': {'pred_time': 4.521916421611657e-06}, 'val_loss': 0.16715799428649775, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170326C0>}\n",
      "[flaml.tune.tune: 05-26 21:18:15] {735} INFO - Number of trials: 68/1000000, 1 RUNNING, 67 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:16] {755} INFO - Brief result: {'pred_time': 5.485794760964133e-06, 'wall_clock_time': 39.077306509017944, 'metric_for_logging': {'pred_time': 5.485794760964133e-06}, 'val_loss': 0.150660326413896, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917032A20>}\n",
      "[flaml.tune.tune: 05-26 21:18:16] {735} INFO - Number of trials: 69/1000000, 1 RUNNING, 68 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:17] {755} INFO - Brief result: {'pred_time': 3.512521808067064e-05, 'wall_clock_time': 40.20795440673828, 'metric_for_logging': {'pred_time': 3.512521808067064e-05}, 'val_loss': 0.16715799428649775, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917033020>}\n",
      "[flaml.tune.tune: 05-26 21:18:17] {735} INFO - Number of trials: 70/1000000, 1 RUNNING, 69 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:18] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 40.924941301345825, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.1647336030598855, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917033890>}\n",
      "[flaml.tune.tune: 05-26 21:18:18] {735} INFO - Number of trials: 71/1000000, 1 RUNNING, 70 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:19] {755} INFO - Brief result: {'pred_time': 6.482776509363877e-05, 'wall_clock_time': 41.991517066955566, 'metric_for_logging': {'pred_time': 6.482776509363877e-05}, 'val_loss': 0.1931152577371509, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917033140>}\n",
      "[flaml.tune.tune: 05-26 21:18:19] {735} INFO - Number of trials: 72/1000000, 1 RUNNING, 71 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:20] {755} INFO - Brief result: {'pred_time': 4.227192457898523e-05, 'wall_clock_time': 42.65623903274536, 'metric_for_logging': {'pred_time': 4.227192457898523e-05}, 'val_loss': 0.16676879342135822, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170336E0>}\n",
      "[flaml.tune.tune: 05-26 21:18:20] {735} INFO - Number of trials: 73/1000000, 1 RUNNING, 72 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:21] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 43.76026105880737, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.18127568907579486, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917060D40>}\n",
      "[flaml.tune.tune: 05-26 21:18:21] {735} INFO - Number of trials: 74/1000000, 1 RUNNING, 73 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:23] {755} INFO - Brief result: {'pred_time': 6.7292974236306175e-06, 'wall_clock_time': 45.60754036903381, 'metric_for_logging': {'pred_time': 6.7292974236306175e-06}, 'val_loss': 0.16901670122188367, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917060E90>}\n",
      "[flaml.tune.tune: 05-26 21:18:23] {735} INFO - Number of trials: 75/1000000, 1 RUNNING, 74 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:23] {755} INFO - Brief result: {'pred_time': 7.553526159448205e-05, 'wall_clock_time': 46.0247745513916, 'metric_for_logging': {'pred_time': 7.553526159448205e-05}, 'val_loss': 0.15958452597796863, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917060590>}\n",
      "[flaml.tune.tune: 05-26 21:18:23] {735} INFO - Number of trials: 76/1000000, 1 RUNNING, 75 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:25] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 47.593047857284546, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.15912537528084858, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917062060>}\n",
      "[flaml.tune.tune: 05-26 21:18:25] {735} INFO - Number of trials: 77/1000000, 1 RUNNING, 76 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:25] {755} INFO - Brief result: {'pred_time': 3.552816130898216e-05, 'wall_clock_time': 48.07331967353821, 'metric_for_logging': {'pred_time': 3.552816130898216e-05}, 'val_loss': 0.2028238747170529, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917061B50>}\n",
      "[flaml.tune.tune: 05-26 21:18:25] {735} INFO - Number of trials: 78/1000000, 1 RUNNING, 77 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:26] {755} INFO - Brief result: {'pred_time': 3.520665543802668e-05, 'wall_clock_time': 48.93838381767273, 'metric_for_logging': {'pred_time': 3.520665543802668e-05}, 'val_loss': 0.1757008273666127, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917062030>}\n",
      "[flaml.tune.tune: 05-26 21:18:26] {735} INFO - Number of trials: 79/1000000, 1 RUNNING, 78 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:27] {755} INFO - Brief result: {'pred_time': 1.532924918037391e-05, 'wall_clock_time': 49.78794527053833, 'metric_for_logging': {'pred_time': 1.532924918037391e-05}, 'val_loss': 0.17292046144505163, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170630E0>}\n",
      "[flaml.tune.tune: 05-26 21:18:27] {735} INFO - Number of trials: 80/1000000, 1 RUNNING, 79 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:27] {755} INFO - Brief result: {'pred_time': 4.197057713283582e-05, 'wall_clock_time': 50.49092149734497, 'metric_for_logging': {'pred_time': 4.197057713283582e-05}, 'val_loss': 0.17138576213139936, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170636E0>}\n",
      "[flaml.tune.tune: 05-26 21:18:27] {735} INFO - Number of trials: 81/1000000, 1 RUNNING, 80 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:28] {755} INFO - Brief result: {'pred_time': 1.1394782499833541e-05, 'wall_clock_time': 51.57304644584656, 'metric_for_logging': {'pred_time': 1.1394782499833541e-05}, 'val_loss': 0.200764271864219, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917063C80>}\n",
      "[flaml.tune.tune: 05-26 21:18:28] {735} INFO - Number of trials: 82/1000000, 1 RUNNING, 81 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:29] {755} INFO - Brief result: {'pred_time': 6.898767005678826e-05, 'wall_clock_time': 52.23733162879944, 'metric_for_logging': {'pred_time': 6.898767005678826e-05}, 'val_loss': 0.17194745928220279, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917062ED0>}\n",
      "[flaml.tune.tune: 05-26 21:18:29] {735} INFO - Number of trials: 83/1000000, 1 RUNNING, 82 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:30] {755} INFO - Brief result: {'pred_time': 5.583870276976167e-05, 'wall_clock_time': 53.39003586769104, 'metric_for_logging': {'pred_time': 5.583870276976167e-05}, 'val_loss': 0.186104465877073, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917098D70>}\n",
      "[flaml.tune.tune: 05-26 21:18:30] {735} INFO - Number of trials: 84/1000000, 1 RUNNING, 83 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:31] {755} INFO - Brief result: {'pred_time': 1.037066633051092e-05, 'wall_clock_time': 54.35644268989563, 'metric_for_logging': {'pred_time': 1.037066633051092e-05}, 'val_loss': 0.16027003433137757, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917099430>}\n",
      "[flaml.tune.tune: 05-26 21:18:31] {735} INFO - Number of trials: 85/1000000, 1 RUNNING, 84 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:32] {755} INFO - Brief result: {'pred_time': 1.1388822035356001e-05, 'wall_clock_time': 55.10476851463318, 'metric_for_logging': {'pred_time': 1.1388822035356001e-05}, 'val_loss': 0.1692858681753447, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917099B50>}\n",
      "[flaml.tune.tune: 05-26 21:18:32] {735} INFO - Number of trials: 86/1000000, 1 RUNNING, 85 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:33] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 55.94050312042236, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.1793284256531216, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170603B0>}\n",
      "[flaml.tune.tune: 05-26 21:18:33] {735} INFO - Number of trials: 87/1000000, 1 RUNNING, 86 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:34] {755} INFO - Brief result: {'pred_time': 7.652341406240649e-06, 'wall_clock_time': 56.83720779418945, 'metric_for_logging': {'pred_time': 7.652341406240649e-06}, 'val_loss': 0.1632394046989499, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x000002691709A6F0>}\n",
      "[flaml.tune.tune: 05-26 21:18:34] {735} INFO - Number of trials: 88/1000000, 1 RUNNING, 87 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:34] {755} INFO - Brief result: {'pred_time': 3.477985208684748e-05, 'wall_clock_time': 57.39130926132202, 'metric_for_logging': {'pred_time': 3.477985208684748e-05}, 'val_loss': 0.17318808950220904, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x000002691709AED0>}\n",
      "[flaml.tune.tune: 05-26 21:18:34] {735} INFO - Number of trials: 89/1000000, 1 RUNNING, 88 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:36] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 58.68034553527832, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.15981305207904895, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170991F0>}\n",
      "[flaml.tune.tune: 05-26 21:18:36] {735} INFO - Number of trials: 90/1000000, 1 RUNNING, 89 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:38] {755} INFO - Brief result: {'pred_time': 6.817687641490589e-06, 'wall_clock_time': 60.670018911361694, 'metric_for_logging': {'pred_time': 6.817687641490589e-06}, 'val_loss': 0.1731879496025451, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x000002691709B6E0>}\n",
      "[flaml.tune.tune: 05-26 21:18:38] {735} INFO - Number of trials: 91/1000000, 1 RUNNING, 90 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:38] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 61.06879496574402, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.17454574579111853, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x000002691709B2F0>}\n",
      "[flaml.tune.tune: 05-26 21:18:38] {735} INFO - Number of trials: 92/1000000, 1 RUNNING, 91 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:40] {755} INFO - Brief result: {'pred_time': 3.5131647345725065e-05, 'wall_clock_time': 63.17321157455444, 'metric_for_logging': {'pred_time': 3.5131647345725065e-05}, 'val_loss': 0.18096651081844106, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170D0170>}\n",
      "[flaml.tune.tune: 05-26 21:18:40] {735} INFO - Number of trials: 93/1000000, 1 RUNNING, 92 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:40] {755} INFO - Brief result: {'pred_time': 4.603834756182942e-05, 'wall_clock_time': 63.54993748664856, 'metric_for_logging': {'pred_time': 4.603834756182942e-05}, 'val_loss': 0.16792772223761118, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170D0560>}\n",
      "[flaml.tune.tune: 05-26 21:18:40] {735} INFO - Number of trials: 94/1000000, 1 RUNNING, 93 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:41] {755} INFO - Brief result: {'pred_time': 4.285857066192471e-05, 'wall_clock_time': 64.33734798431396, 'metric_for_logging': {'pred_time': 4.285857066192471e-05}, 'val_loss': 0.16178137040114832, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170D0CE0>}\n",
      "[flaml.tune.tune: 05-26 21:18:41] {735} INFO - Number of trials: 95/1000000, 1 RUNNING, 94 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:42] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 65.25759720802307, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.164340694853651, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170D1550>}\n",
      "[flaml.tune.tune: 05-26 21:18:42] {735} INFO - Number of trials: 96/1000000, 1 RUNNING, 95 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:43] {755} INFO - Brief result: {'pred_time': 4.2518160559914324e-05, 'wall_clock_time': 65.97072005271912, 'metric_for_logging': {'pred_time': 4.2518160559914324e-05}, 'val_loss': 0.1645160590824261, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170D2090>}\n",
      "[flaml.tune.tune: 05-26 21:18:43] {735} INFO - Number of trials: 97/1000000, 1 RUNNING, 96 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:44] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 67.00478982925415, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.19697844705777018, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170D26C0>}\n",
      "[flaml.tune.tune: 05-26 21:18:44] {735} INFO - Number of trials: 98/1000000, 1 RUNNING, 97 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:45] {755} INFO - Brief result: {'pred_time': 5.650788210750965e-06, 'wall_clock_time': 67.70100498199463, 'metric_for_logging': {'pred_time': 5.650788210750965e-06}, 'val_loss': 0.1614331601375494, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170D2AB0>}\n",
      "[flaml.tune.tune: 05-26 21:18:45] {735} INFO - Number of trials: 99/1000000, 1 RUNNING, 98 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:46] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 68.80525755882263, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.1846243274323655, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170D30B0>}\n",
      "[flaml.tune.tune: 05-26 21:18:46] {735} INFO - Number of trials: 100/1000000, 1 RUNNING, 99 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:46] {755} INFO - Brief result: {'pred_time': 3.512468230858278e-05, 'wall_clock_time': 69.44375491142273, 'metric_for_logging': {'pred_time': 3.512468230858278e-05}, 'val_loss': 0.18212194214309496, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170D3560>}\n",
      "[flaml.tune.tune: 05-26 21:18:46] {735} INFO - Number of trials: 101/1000000, 1 RUNNING, 100 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:48] {755} INFO - Brief result: {'pred_time': 4.00543212890625e-05, 'wall_clock_time': 70.62120056152344, 'metric_for_logging': {'pred_time': 4.00543212890625e-05}, 'val_loss': 0.17655155722315957, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269170D3D10>}\n",
      "[flaml.tune.tune: 05-26 21:18:48] {735} INFO - Number of trials: 102/1000000, 1 RUNNING, 101 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:48] {755} INFO - Brief result: {'pred_time': 4.567341371016069e-06, 'wall_clock_time': 71.47364211082458, 'metric_for_logging': {'pred_time': 4.567341371016069e-06}, 'val_loss': 0.16477676210621744, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917110380>}\n",
      "[flaml.tune.tune: 05-26 21:18:48] {735} INFO - Number of trials: 103/1000000, 1 RUNNING, 102 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:49] {755} INFO - Brief result: {'pred_time': 4.803614426438485e-05, 'wall_clock_time': 72.36320376396179, 'metric_for_logging': {'pred_time': 4.803614426438485e-05}, 'val_loss': 0.17197781750928237, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171105C0>}\n",
      "[flaml.tune.tune: 05-26 21:18:49] {735} INFO - Number of trials: 104/1000000, 1 RUNNING, 103 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:51] {755} INFO - Brief result: {'pred_time': 3.161384696492866e-05, 'wall_clock_time': 73.70245337486267, 'metric_for_logging': {'pred_time': 3.161384696492866e-05}, 'val_loss': 0.15515229477418796, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917110830>}\n",
      "[flaml.tune.tune: 05-26 21:18:51] {735} INFO - Number of trials: 105/1000000, 1 RUNNING, 104 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:51] {755} INFO - Brief result: {'pred_time': 4.9472585761875857e-05, 'wall_clock_time': 74.4188666343689, 'metric_for_logging': {'pred_time': 4.9472585761875857e-05}, 'val_loss': 0.17717005363753116, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171118B0>}\n",
      "[flaml.tune.tune: 05-26 21:18:51] {735} INFO - Number of trials: 106/1000000, 1 RUNNING, 105 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:52] {755} INFO - Brief result: {'pred_time': 1.1312273598301764e-05, 'wall_clock_time': 75.41543292999268, 'metric_for_logging': {'pred_time': 1.1312273598301764e-05}, 'val_loss': 0.19544752503504487, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917111E20>}\n",
      "[flaml.tune.tune: 05-26 21:18:52] {735} INFO - Number of trials: 107/1000000, 1 RUNNING, 106 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:53] {755} INFO - Brief result: {'pred_time': 4.1868981350673724e-05, 'wall_clock_time': 76.18358159065247, 'metric_for_logging': {'pred_time': 4.1868981350673724e-05}, 'val_loss': 0.16577585555639493, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917111760>}\n",
      "[flaml.tune.tune: 05-26 21:18:53] {735} INFO - Number of trials: 108/1000000, 1 RUNNING, 107 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:53] {755} INFO - Brief result: {'pred_time': 4.2262231974850146e-05, 'wall_clock_time': 76.52837705612183, 'metric_for_logging': {'pred_time': 4.2262231974850146e-05}, 'val_loss': 0.18452639766759285, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917112B10>}\n",
      "[flaml.tune.tune: 05-26 21:18:53] {735} INFO - Number of trials: 109/1000000, 1 RUNNING, 108 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:56] {755} INFO - Brief result: {'pred_time': 1.4798749576915396e-05, 'wall_clock_time': 78.95502710342407, 'metric_for_logging': {'pred_time': 1.4798749576915396e-05}, 'val_loss': 0.17055196013419174, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917112D20>}\n",
      "[flaml.tune.tune: 05-26 21:18:56] {735} INFO - Number of trials: 110/1000000, 1 RUNNING, 109 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:58] {755} INFO - Brief result: {'pred_time': 1.1305832156608979e-05, 'wall_clock_time': 81.36434507369995, 'metric_for_logging': {'pred_time': 1.1305832156608979e-05}, 'val_loss': 0.15699722159267376, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917113560>}\n",
      "[flaml.tune.tune: 05-26 21:18:58] {735} INFO - Number of trials: 111/1000000, 1 RUNNING, 110 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:59] {755} INFO - Brief result: {'pred_time': 9.039546666520366e-06, 'wall_clock_time': 81.72124361991882, 'metric_for_logging': {'pred_time': 9.039546666520366e-06}, 'val_loss': 0.17465388823136047, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917113D10>}\n",
      "[flaml.tune.tune: 05-26 21:18:59] {735} INFO - Number of trials: 112/1000000, 1 RUNNING, 111 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:18:59] {755} INFO - Brief result: {'pred_time': 3.5599686882712624e-05, 'wall_clock_time': 82.17068767547607, 'metric_for_logging': {'pred_time': 3.5599686882712624e-05}, 'val_loss': 0.1899135140277393, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917113650>}\n",
      "[flaml.tune.tune: 05-26 21:18:59] {735} INFO - Number of trials: 113/1000000, 1 RUNNING, 112 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:01] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 84.45241189002991, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.17466305165934995, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171488F0>}\n",
      "[flaml.tune.tune: 05-26 21:19:01] {735} INFO - Number of trials: 114/1000000, 1 RUNNING, 113 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:02] {755} INFO - Brief result: {'pred_time': 7.068172051543723e-05, 'wall_clock_time': 85.41762328147888, 'metric_for_logging': {'pred_time': 7.068172051543723e-05}, 'val_loss': 0.19648502094297973, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171491C0>}\n",
      "[flaml.tune.tune: 05-26 21:19:02] {735} INFO - Number of trials: 115/1000000, 1 RUNNING, 114 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:03] {755} INFO - Brief result: {'pred_time': 1.8609952147330887e-05, 'wall_clock_time': 86.21029782295227, 'metric_for_logging': {'pred_time': 1.8609952147330887e-05}, 'val_loss': 0.16924424802531624, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917112D80>}\n",
      "[flaml.tune.tune: 05-26 21:19:03] {735} INFO - Number of trials: 116/1000000, 1 RUNNING, 115 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:04] {755} INFO - Brief result: {'pred_time': 7.1709806268865405e-06, 'wall_clock_time': 86.85302090644836, 'metric_for_logging': {'pred_time': 7.1709806268865405e-06}, 'val_loss': 0.1656225954745257, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917149AF0>}\n",
      "[flaml.tune.tune: 05-26 21:19:04] {735} INFO - Number of trials: 117/1000000, 1 RUNNING, 116 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:05] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 87.9889509677887, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.19558518630438246, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x000002691714A420>}\n",
      "[flaml.tune.tune: 05-26 21:19:05] {735} INFO - Number of trials: 118/1000000, 1 RUNNING, 117 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:06] {755} INFO - Brief result: {'pred_time': 0.00011303616617259259, 'wall_clock_time': 89.1881673336029, 'metric_for_logging': {'pred_time': 0.00011303616617259259}, 'val_loss': 0.1636672178713427, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917149B20>}\n",
      "[flaml.tune.tune: 05-26 21:19:06] {735} INFO - Number of trials: 119/1000000, 1 RUNNING, 118 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:07] {755} INFO - Brief result: {'pred_time': 3.5246935757723716e-05, 'wall_clock_time': 89.8355929851532, 'metric_for_logging': {'pred_time': 3.5246935757723716e-05}, 'val_loss': 0.17546691512846985, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x000002691714ACC0>}\n",
      "[flaml.tune.tune: 05-26 21:19:07] {735} INFO - Number of trials: 120/1000000, 1 RUNNING, 119 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:08] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 91.34517979621887, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.17445823855131098, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x000002691714B560>}\n",
      "[flaml.tune.tune: 05-26 21:19:08] {735} INFO - Number of trials: 121/1000000, 1 RUNNING, 120 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:09] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 91.85198283195496, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.16806741205207626, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917148B90>}\n",
      "[flaml.tune.tune: 05-26 21:19:09] {735} INFO - Number of trials: 122/1000000, 1 RUNNING, 121 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:09] {755} INFO - Brief result: {'pred_time': 2.9659271240234376e-05, 'wall_clock_time': 92.57097315788269, 'metric_for_logging': {'pred_time': 2.9659271240234376e-05}, 'val_loss': 0.18280773029583186, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x000002691714BCB0>}\n",
      "[flaml.tune.tune: 05-26 21:19:09] {735} INFO - Number of trials: 123/1000000, 1 RUNNING, 122 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:11] {755} INFO - Brief result: {'pred_time': 7.018175383266804e-05, 'wall_clock_time': 93.59818577766418, 'metric_for_logging': {'pred_time': 7.018175383266804e-05}, 'val_loss': 0.16984868452345978, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917184980>}\n",
      "[flaml.tune.tune: 05-26 21:19:11] {735} INFO - Number of trials: 124/1000000, 1 RUNNING, 123 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:11] {755} INFO - Brief result: {'pred_time': 6.67178716065326e-05, 'wall_clock_time': 94.25459957122803, 'metric_for_logging': {'pred_time': 6.67178716065326e-05}, 'val_loss': 0.19461624123178853, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917184B60>}\n",
      "[flaml.tune.tune: 05-26 21:19:11] {735} INFO - Number of trials: 125/1000000, 1 RUNNING, 124 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:12] {755} INFO - Brief result: {'pred_time': 0.0, 'wall_clock_time': 95.3694167137146, 'metric_for_logging': {'pred_time': 0.0}, 'val_loss': 0.1711640211640212, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171846B0>}\n",
      "[flaml.tune.tune: 05-26 21:19:12] {735} INFO - Number of trials: 126/1000000, 1 RUNNING, 125 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:13] {755} INFO - Brief result: {'pred_time': 6.901676004583186e-06, 'wall_clock_time': 96.1907365322113, 'metric_for_logging': {'pred_time': 6.901676004583186e-06}, 'val_loss': 0.16963142034532835, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917185D00>}\n",
      "[flaml.tune.tune: 05-26 21:19:13] {735} INFO - Number of trials: 127/1000000, 1 RUNNING, 126 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:14] {755} INFO - Brief result: {'pred_time': 1.072504303672097e-05, 'wall_clock_time': 97.07470178604126, 'metric_for_logging': {'pred_time': 1.072504303672097e-05}, 'val_loss': 0.17303364027319604, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917186000>}\n",
      "[flaml.tune.tune: 05-26 21:19:14] {735} INFO - Number of trials: 128/1000000, 1 RUNNING, 127 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:15] {755} INFO - Brief result: {'pred_time': 5.8632875974380445e-05, 'wall_clock_time': 97.66391205787659, 'metric_for_logging': {'pred_time': 5.8632875974380445e-05}, 'val_loss': 0.20084975055889914, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917186C00>}\n",
      "[flaml.tune.tune: 05-26 21:19:15] {735} INFO - Number of trials: 129/1000000, 1 RUNNING, 128 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:16] {755} INFO - Brief result: {'pred_time': 3.412420099431818e-05, 'wall_clock_time': 98.8702073097229, 'metric_for_logging': {'pred_time': 3.412420099431818e-05}, 'val_loss': 0.1664487029902154, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917187230>}\n",
      "[flaml.tune.tune: 05-26 21:19:16] {735} INFO - Number of trials: 130/1000000, 1 RUNNING, 129 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:16] {755} INFO - Brief result: {'pred_time': 8.98918409026071e-06, 'wall_clock_time': 99.38157844543457, 'metric_for_logging': {'pred_time': 8.98918409026071e-06}, 'val_loss': 0.1689491996340225, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x0000026917187F50>}\n",
      "[flaml.tune.tune: 05-26 21:19:16] {735} INFO - Number of trials: 131/1000000, 1 RUNNING, 130 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:18] {755} INFO - Brief result: {'pred_time': 3.5523284565318715e-05, 'wall_clock_time': 100.81961846351624, 'metric_for_logging': {'pred_time': 3.5523284565318715e-05}, 'val_loss': 0.17555952870601205, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171BC3E0>}\n",
      "[flaml.tune.tune: 05-26 21:19:18] {735} INFO - Number of trials: 132/1000000, 1 RUNNING, 131 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:18] {755} INFO - Brief result: {'pred_time': 3.5526535727761007e-05, 'wall_clock_time': 101.23004150390625, 'metric_for_logging': {'pred_time': 3.5526535727761007e-05}, 'val_loss': 0.16987463591112453, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171BCCE0>}\n",
      "[flaml.tune.tune: 05-26 21:19:18] {735} INFO - Number of trials: 133/1000000, 1 RUNNING, 132 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:20] {755} INFO - Brief result: {'pred_time': 9.02524520476578e-06, 'wall_clock_time': 103.078284740448, 'metric_for_logging': {'pred_time': 9.02524520476578e-06}, 'val_loss': 0.17100887243668844, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171BCE30>}\n",
      "[flaml.tune.tune: 05-26 21:19:20] {735} INFO - Number of trials: 134/1000000, 1 RUNNING, 133 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:21] {755} INFO - Brief result: {'pred_time': 4.51749021356756e-06, 'wall_clock_time': 104.21472764015198, 'metric_for_logging': {'pred_time': 4.51749021356756e-06}, 'val_loss': 0.17090730528065273, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171BCC50>}\n",
      "[flaml.tune.tune: 05-26 21:19:21] {735} INFO - Number of trials: 135/1000000, 1 RUNNING, 134 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:22] {755} INFO - Brief result: {'pred_time': 3.585869006896287e-05, 'wall_clock_time': 104.87807512283325, 'metric_for_logging': {'pred_time': 3.585869006896287e-05}, 'val_loss': 0.19218702346676964, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171BDB80>}\n",
      "[flaml.tune.tune: 05-26 21:19:22] {735} INFO - Number of trials: 136/1000000, 1 RUNNING, 135 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:22] {755} INFO - Brief result: {'pred_time': 3.794431686401367e-05, 'wall_clock_time': 105.4445812702179, 'metric_for_logging': {'pred_time': 3.794431686401367e-05}, 'val_loss': 0.20897148565049145, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171BEAE0>}\n",
      "[flaml.tune.tune: 05-26 21:19:22] {735} INFO - Number of trials: 137/1000000, 1 RUNNING, 136 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:24] {755} INFO - Brief result: {'pred_time': 1.7846568246905721e-06, 'wall_clock_time': 106.86112999916077, 'metric_for_logging': {'pred_time': 1.7846568246905721e-06}, 'val_loss': 0.16479970565110702, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171BE8A0>}\n",
      "[flaml.tune.tune: 05-26 21:19:24] {735} INFO - Number of trials: 138/1000000, 1 RUNNING, 137 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:25] {755} INFO - Brief result: {'pred_time': 1.0330209449557654e-05, 'wall_clock_time': 108.01620221138, 'metric_for_logging': {'pred_time': 1.0330209449557654e-05}, 'val_loss': 0.21306439021933468, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171BF8F0>}\n",
      "[flaml.tune.tune: 05-26 21:19:25] {735} INFO - Number of trials: 139/1000000, 1 RUNNING, 138 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:26] {755} INFO - Brief result: {'pred_time': 2.210465344515714e-05, 'wall_clock_time': 108.62745380401611, 'metric_for_logging': {'pred_time': 2.210465344515714e-05}, 'val_loss': 0.1632050593314475, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171BF740>}\n",
      "[flaml.tune.tune: 05-26 21:19:26] {735} INFO - Number of trials: 140/1000000, 1 RUNNING, 139 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:27] {755} INFO - Brief result: {'pred_time': 9.936799920250619e-05, 'wall_clock_time': 109.6951220035553, 'metric_for_logging': {'pred_time': 9.936799920250619e-05}, 'val_loss': 0.1915816776208104, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269138E7F20>}\n",
      "[flaml.tune.tune: 05-26 21:19:27] {735} INFO - Number of trials: 141/1000000, 1 RUNNING, 140 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:27] {755} INFO - Brief result: {'pred_time': 2.253848880498962e-05, 'wall_clock_time': 110.43750619888306, 'metric_for_logging': {'pred_time': 2.253848880498962e-05}, 'val_loss': 0.15898134857680074, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171E8CE0>}\n",
      "[flaml.tune.tune: 05-26 21:19:27] {735} INFO - Number of trials: 142/1000000, 1 RUNNING, 141 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:29] {755} INFO - Brief result: {'pred_time': 9.658896764768888e-05, 'wall_clock_time': 111.66425609588623, 'metric_for_logging': {'pred_time': 9.658896764768888e-05}, 'val_loss': 0.17758863343210257, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171E8E00>}\n",
      "[flaml.tune.tune: 05-26 21:19:29] {735} INFO - Number of trials: 143/1000000, 1 RUNNING, 142 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:29] {755} INFO - Brief result: {'pred_time': 3.552491014653986e-05, 'wall_clock_time': 112.28304767608643, 'metric_for_logging': {'pred_time': 3.552491014653986e-05}, 'val_loss': 0.15848848206066612, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171E9760>}\n",
      "[flaml.tune.tune: 05-26 21:19:29] {735} INFO - Number of trials: 144/1000000, 1 RUNNING, 143 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:31] {755} INFO - Brief result: {'pred_time': 4.305219138849744e-05, 'wall_clock_time': 113.74662733078003, 'metric_for_logging': {'pred_time': 4.305219138849744e-05}, 'val_loss': 0.19773068755088852, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171E9D00>}\n",
      "[flaml.tune.tune: 05-26 21:19:31] {735} INFO - Number of trials: 145/1000000, 1 RUNNING, 144 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:31] {755} INFO - Brief result: {'pred_time': 9.205796745386018e-05, 'wall_clock_time': 114.29898381233215, 'metric_for_logging': {'pred_time': 9.205796745386018e-05}, 'val_loss': 0.1651972305462522, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171E91F0>}\n",
      "[flaml.tune.tune: 05-26 21:19:31] {735} INFO - Number of trials: 146/1000000, 1 RUNNING, 145 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:32] {755} INFO - Brief result: {'pred_time': 6.154296468787344e-05, 'wall_clock_time': 114.8675811290741, 'metric_for_logging': {'pred_time': 6.154296468787344e-05}, 'val_loss': 0.1589366506341652, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171EA570>}\n",
      "[flaml.tune.tune: 05-26 21:19:32] {735} INFO - Number of trials: 147/1000000, 1 RUNNING, 146 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:34] {755} INFO - Brief result: {'pred_time': 6.956836176356937e-05, 'wall_clock_time': 116.96231627464294, 'metric_for_logging': {'pred_time': 6.956836176356937e-05}, 'val_loss': 0.17580323392063213, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171EAD80>}\n",
      "[flaml.tune.tune: 05-26 21:19:34] {735} INFO - Number of trials: 148/1000000, 1 RUNNING, 147 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:35] {755} INFO - Brief result: {'pred_time': 2.377611015132791e-05, 'wall_clock_time': 118.09383845329285, 'metric_for_logging': {'pred_time': 2.377611015132791e-05}, 'val_loss': 0.1875090585032415, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x000002691714AD80>}\n",
      "[flaml.tune.tune: 05-26 21:19:35] {735} INFO - Number of trials: 149/1000000, 1 RUNNING, 148 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:36] {755} INFO - Brief result: {'pred_time': 3.9997200678512683e-05, 'wall_clock_time': 118.95893859863281, 'metric_for_logging': {'pred_time': 3.9997200678512683e-05}, 'val_loss': 0.16093238929040093, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171EB500>}\n",
      "[flaml.tune.tune: 05-26 21:19:36] {735} INFO - Number of trials: 150/1000000, 1 RUNNING, 149 TERMINATED\n",
      "[flaml.tune.tune: 05-26 21:19:38] {755} INFO - Brief result: {'pred_time': 1.670114840623429e-05, 'wall_clock_time': 121.3650050163269, 'metric_for_logging': {'pred_time': 1.670114840623429e-05}, 'val_loss': 0.16881426640813213, 'trained_estimator': <flaml.automl.model.LGBMEstimator object at 0x00000269171EB560>}\n",
      "[flaml.automl.logger: 05-26 21:19:38] {2494} INFO - selected model: None\n",
      "[flaml.automl.logger: 05-26 21:19:38] {2628} INFO - retrain lgbm for 0.2s\n",
      "[flaml.automl.logger: 05-26 21:19:38] {2631} INFO - retrained model: LGBMClassifier(colsample_bytree=0.7714909665433299,\n",
      "               learning_rate=0.414969127271611, max_bin=1023,\n",
      "               min_child_samples=9, n_estimators=1, n_jobs=-1, num_leaves=7,\n",
      "               reg_alpha=0.005456783453304973, reg_lambda=0.12084029088844267,\n",
      "               verbose=-1)\n",
      "[flaml.automl.logger: 05-26 21:19:38] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 05-26 21:19:38] {1932} INFO - Time taken to find the best model: 39.077306509017944\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = mphd.pre_processing.train_test_split(df = df,\n",
    "                                                                        independent_variables=independent_variables,\n",
    "                                                                        dependent_variable = dependent_variable,\n",
    "                                                                        test_size = 0.2)\n",
    "# \"estimator_list\": ['lgbm', 'lgbm_spark', 'xgboost', 'catboost', 'rf'],\n",
    "    # \"task\": 'regression',  # task type    \n",
    "settings = {\n",
    "    \"time_budget\": 120,  # total running time in seconds\n",
    "    \"metric\": 'roc_auc',  # primary metrics for regression can be chosen from: ['mae','mse','r2','rmse','mape']\n",
    "    \"estimator_list\": ['lgbm',],  # list of ML learners; we tune lightgbm in this example\n",
    "    \"task\": 'classification',  # task type    \n",
    "    \"log_file_name\": None,  # flaml log file\n",
    "    \"seed\": 7654321,    # random seed\n",
    "    \"use_spark\": True,  # whether to use Spark for distributed training\n",
    "    \"n_concurrent_trials\": 2,  # the maximum number of concurrent trials\n",
    "}\n",
    "\n",
    "automl = mphd.machine_learning.automl(X_train=X_train, y_train=y_train, **settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparmeter config: {'n_estimators': 21, 'num_leaves': 7, 'min_child_samples': 9, 'learning_rate': 0.414969127271611, 'log_max_bin': 10, 'colsample_bytree': 0.7714909665433299, 'reg_alpha': 0.005456783453304973, 'reg_lambda': 0.12084029088844267}\n",
      "Best r2 on validation data: 0.8493\n",
      "Training duration of best run: 0.204 s\n",
      "r2 = -0.017570664629488197\n",
      "mse = 0.21621621621621623\n",
      "mae = 0.21621621621621623\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.7714909665433299,\n",
       "               learning_rate=0.414969127271611, max_bin=1023,\n",
       "               min_child_samples=9, n_estimators=1, n_jobs=-1, num_leaves=7,\n",
       "               reg_alpha=0.005456783453304973, reg_lambda=0.12084029088844267,\n",
       "               verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(colsample_bytree=0.7714909665433299,\n",
       "               learning_rate=0.414969127271611, max_bin=1023,\n",
       "               min_child_samples=9, n_estimators=1, n_jobs=-1, num_leaves=7,\n",
       "               reg_alpha=0.005456783453304973, reg_lambda=0.12084029088844267,\n",
       "               verbose=-1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.7714909665433299,\n",
       "               learning_rate=0.414969127271611, max_bin=1023,\n",
       "               min_child_samples=9, n_estimators=1, n_jobs=-1, num_leaves=7,\n",
       "               reg_alpha=0.005456783453304973, reg_lambda=0.12084029088844267,\n",
       "               verbose=-1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mphd.analyse_ml.analyse_automl(automl=automl, X_test = X_test, y_test = y_test)\n",
    "automl.model.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna.integration.lightgbm as lgb\n",
    "from optuna.integration import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "from lightgbm import log_evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "dval = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"binary_logloss\",\n",
    "        \"verbosity\": -1,\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "    }\n",
    "\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    valid_sets=[dtrain, dval],\n",
    "    callbacks=[early_stopping(100), log_evaluation(100)],\n",
    ")\n",
    "\n",
    "prediction = np.rint(model.predict(X_test, num_iteration=model.best_iteration))\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "\n",
    "best_params = model.params\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"  Accuracy = {}\".format(accuracy))\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the gender\n",
    "df = mphd.categorical_data.label_encode(df = df, columns = \"Gender\", convert_numeric=True)\n",
    "# \"Gender\":{0:\"Female\", 1:\"Male\"}\n",
    "\n",
    "# Check for duplication\n",
    "duplicated_df, to_drop_duplicated_df = mphd.pre_processing.check_duplication(df)\n",
    "\n",
    "# Check for missing value\n",
    "missing_df = mphd.missing_values.analyse_missing_row(df)\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To fix AGR == ' ' issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Globulin for every patient ID with globulin = tp - alb based on resource below:\n",
    "# https://www.ncbi.nlm.nih.gov/books/NBK204/#:~:text=The%20total%20globulin%20fraction%20is,of%20further%20fractionating%20serum%20proteins\n",
    "\n",
    "# To check the truthness of this on the data\n",
    "# Create a deep copy of the df with AGR not null first\n",
    "temp_df = df.query(\"AGR.notnull()\").copy(deep = True)\n",
    "\n",
    "# Calculatet the globulin and agr_ratio\n",
    "def calculate_agr(df:pd.DataFrame, column_name:str):\n",
    "    df.loc[:,column_name] = df.loc[:,\"ALB\"] / (df.loc[:,\"TP\"] - df.loc[:,\"ALB\"])\n",
    "    return df\n",
    "\n",
    "# Calculate the approximate agr\n",
    "temp_df = calculate_agr(df = temp_df, column_name = \"agr_new\")\n",
    "# Check for float similarity\n",
    "temp_df.loc[:,\"agr_similarity\"] = temp_df.loc[:,(\"AGR\", \"agr_new\",)].apply(lambda x: np.isclose(float(x[0]), x[1], rtol = 0.1), axis = 1)\n",
    "\n",
    "# Pivot the information\n",
    "pt = temp_df.pivot_table(index = \"agr_similarity\", values = \"Patient_ID\", aggfunc = len, margins = True).rename(columns={\"Patient_ID\":\"count\"})\n",
    "# Calculate percentage\n",
    "pt.loc[:,\"percentage\"] = round(pt.loc[:,\"count\"] / pt.loc[\"All\", \"count\"] * 100, 2)\n",
    "\n",
    "print(pt.to_markdown(tablefmt = \"pretty\"))\n",
    "\n",
    "# Check on the not similarity result\n",
    "temp_df.query(\"agr_similarity == False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial to impute with calculation\n",
    "missing_df = calculate_agr(df = missing_df, column_name=\"AGR\")\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute with MICE\n",
    "# https://medium.com/@brijesh_soni/topic-9-mice-or-multivariate-imputation-with-chain-equation-f8fd435ca91#:~:text=MICE%20stands%20for%20Multivariate%20Imputation,produce%20a%20final%20imputed%20dataset.\n",
    "\n",
    "df = mphd.missing_values.mice_imputation(df = df, columns = \"AGR\")\n",
    "# Check on the imputated value\n",
    "df.loc[missing_df.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__intepretation__:\n",
    "\n",
    "For imputation, despite the logic of how AGR being calculated, there is a lot of noise in the data for AGR value, therefore we would use MICE for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse Encode\n",
    "data = mphd.categorical_data.reverse_encode(df = df, json_dict=data_dictionary)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continous Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for normal distribution\n",
    "normal_distribution_list, abnormal_distribution_list = mphd.continous_data.descriptive_analysis(df = df, \n",
    "                                                                                                independent_variables=independent_continous, \n",
    "                                                                                                dependent_variables = dependent_variable,\n",
    "                                                                                                descriptive_type = \"continous\",\n",
    "                                                                                                plot_dependent_variables = False,\n",
    "                                                                                                plot_correlation = False, \n",
    "                                                                                                round = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_summary = mphd.categorical_data.categorical_descriptive_analysis(data,\n",
    "                                                                             independent_variables = independent_categorical, \n",
    "                                                                             dependent_variables = dependent_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "# set acceptable p value\n",
    "acceptable_p_value = 0.05\n",
    "\n",
    "# For binominal logistic regression with 2 different depression score outcome along with all independent variable are categorized\n",
    "logistic_models, summary_logistic_models = mphd.regression.regression_list(df = df, mode = \"sm.Logit\",\n",
    "                                                                                   independent_variables = independent_demographic + independent_investigations,\n",
    "                                                                                   dependent_variables = dependent_variable,\n",
    "                                                                                   p_value_cut_off = acceptable_p_value)\n",
    "\n",
    "# To display some information\n",
    "columns_to_display = (\"pseudo_r_2\", \"log_likelihood\", \"llr_p_value\", \"aic_akaike_information_criterion\", \"bic_bayesin_information_criterion\", \"coeff_all_significant\")\n",
    "summary_logistic_short = mphd.regression.analyse_model_summary(summary_logistic_models.loc[:,(\"variables\", \"num_variables\") + columns_to_display + \n",
    "                                                                                      (\"roc\", \"shapiro_residual\", \n",
    "                                                                                       \"Lagrange_Multiplier\", \"Lagrange_Multiplier_p-value\",\n",
    "                                                                                       \"F-statistic\", \"F-statistic_p-value\")], \n",
    "                                                      top_count = 3,\n",
    "                                                      parameters= {\"aic_akaike_information_criterion\": True,\n",
    "                                                                   \"bic_bayesin_information_criterion\": True,\n",
    "                                                                   \"pseudo_r_2\": False, \n",
    "                                                                   \"roc\":False})\n",
    "print(summary_logistic_short.round(4).to_markdown(tablefmt = \"pretty\"))\n",
    "print(logistic_models[2893].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "num_cols = ['age', 'bmi', 'sys_bp', 'dias_bp', 'hba1c', 'ldl']\n",
    "cat_cols = ['sex', 'ethnic', 'retinopathy', 'ihd', 'cevd', 'nephropathy']\n",
    "\n",
    "n_estimators = [100, 300]\n",
    "max_depth = [3,4,5]\n",
    "min_child_weight = range(1,3,1)\n",
    "booster = ['gbdt']\n",
    "base_score = [0.5,0.6]\n",
    "learning_rate = [0.1,0.2]\n",
    "objective = ['binary']\n",
    "seed = [27]\n",
    "gamma= [0.7,0.8,0.9]\n",
    "colsample_bytree=[0.7,0.8,0.9]\n",
    "subsample=[0.6,0.7,0.8]\n",
    "reg_alpha = [1e-5,0.01,0.03]\n",
    "weights = np.linspace(0.3, 0.9, 2)\n",
    "num_leaves = [6]\n",
    "\n",
    "lgbm_params = {'classifier__n_estimators': n_estimators, 'classifier__max_depth': max_depth,\n",
    "               'classifier__learning_rate' : learning_rate, 'classifier__min_child_weight' : min_child_weight, \n",
    "               'classifier__boosting_type' : booster, 'classifier__seed':seed,'smote__sampling_strategy': weights,\n",
    "               'classifier__reg_alpha':reg_alpha, 'classifier__num_leaves':num_leaves}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:,independent_demographic+independent_investigations],\n",
    "                                                    df.loc[:,dependent_variable],\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=df.loc[:,dependent_variable],\n",
    "                                                    random_state=11)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', RobustScaler(), independent_continous),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([('smote', SMOTE(random_state=11)),\n",
    "                     ('scaler', preprocessor),\n",
    "                     ('classifier', LGBMClassifier())])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                   shuffle=True,\n",
    "                                   random_state=11)\n",
    "    \n",
    "param_grid = lgbm_params\n",
    "grid_search = GridSearchCV(estimator=pipeline,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=stratified_kfold,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "model = grid_search.fit(X_train, y_train, num_boost_round=1000, early_stopping_rounds=50, verbose_eval=100)\n",
    "model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
